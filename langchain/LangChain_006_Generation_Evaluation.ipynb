{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4019d1fe",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608326bb",
   "metadata": {},
   "source": [
    "`(1) LangSmith 설정 확인`\n",
    "- .env 파일에 아래 내용을 반영\n",
    "    - LANGCHAIN_TRACING_V2=true  \n",
    "    - LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"  \n",
    "    - LANGCHAIN_API_KEY=\"인증키를 입력하세요\"  \n",
    "    - LANGCHAIN_PROJECT=\"프로젝트명\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc3cefd",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ace4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d6566",
   "metadata": {},
   "source": [
    "`(3) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7801daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langsmith 추척 여부:  None\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
    "print(\"langsmith 추척 여부: \", os.getenv('LANGCHAIN_TRACING_V2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc341c8c",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a116eb7",
   "metadata": {},
   "source": [
    "`(1) Raw Documents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adad21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# 문서를 로드\n",
    "from langchain_core.documents import Document\n",
    "import json\n",
    "\n",
    "final_docs = []\n",
    "\n",
    "with open('./data/final_docs_ver2.jsonl', 'rb') as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        doc = Document(page_content=item['page_content'], metadata=item['metadata'])\n",
    "        final_docs.append(doc)\n",
    "\n",
    "print(len(final_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc73b2",
   "metadata": {},
   "source": [
    "`(2) Test Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b162940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>source</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>리비안의 초기 모델은 무엇인가요?</td>\n",
       "      <td>리비안의 초기 모델은 스포츠카 R1입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1의 좌석 구성은 어떻게 되나요?</td>\n",
       "      <td>R1은 2+2 좌석 구성입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1은 어떤 구조를 특징으로 하나요?</td>\n",
       "      <td>R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...</td>\n",
       "      <td>['data/테슬라_KR.txt']</td>\n",
       "      <td>['1']</td>\n",
       "      <td>테슬라는 어디에 본사를 두고 있나요?</td>\n",
       "      <td>테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...</td>\n",
       "      <td>['data/테슬라_KR.txt']</td>\n",
       "      <td>['1']</td>\n",
       "      <td>테슬라는 언제 설립되었나요?</td>\n",
       "      <td>테슬라는 2003년에 설립되었습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context                   source  \\\n",
       "0  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "1  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "2  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "3  ['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...  ['data/테슬라_KR.txt']   \n",
       "4  ['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...  ['data/테슬라_KR.txt']   \n",
       "\n",
       "  doc_id              question                                        answer  \n",
       "0  ['0']    리비안의 초기 모델은 무엇인가요?                       리비안의 초기 모델은 스포츠카 R1입니다.  \n",
       "1  ['0']   R1의 좌석 구성은 어떻게 되나요?                             R1은 2+2 좌석 구성입니다.  \n",
       "2  ['0']  R1은 어떤 구조를 특징으로 하나요?  R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.  \n",
       "3  ['1']  테슬라는 어디에 본사를 두고 있나요?                   테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.  \n",
       "4  ['1']       테슬라는 언제 설립되었나요?                          테슬라는 2003년에 설립되었습니다.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터셋에 대한 QA 생성 결과를 리뷰한 후 다시 로드\n",
    "import pandas as pd\n",
    "\n",
    "df_qa_test = pd.read_excel(\"./data/qa_test_revised.xlsx\")\n",
    "\n",
    "df_qa_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d2368",
   "metadata": {},
   "source": [
    "`(3) 검색도구 정의`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9a519",
   "metadata": {},
   "source": [
    "-  BM25 검색기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d9739e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "검색 결과:\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.) [출처: 리비안_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BM25 검색기를 사용하기 위한 준비\n",
    "from krag.tokenizers import KiwiTokenizer\n",
    "from krag.retrievers import KiWiBM25RetrieverWithScore\n",
    "\n",
    "kiwi_tokenizer = KiwiTokenizer(model_type='knlm', typos='basic')\n",
    "\n",
    "bm25_db = KiWiBM25RetrieverWithScore(\n",
    "        documents=final_docs, \n",
    "        kiwi_tokenizer=kiwi_tokenizer, \n",
    "        k=2, \n",
    "        threshold=0.0,\n",
    "    )\n",
    "\n",
    "# BM25 검색기를 사용하여 문서 검색\n",
    "query = \"테슬라의 회장은 누구인가요?\"\n",
    "retrieved_docs = bm25_db.invoke(query, 2)\n",
    "\n",
    "# 검색 결과 출력 \n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48202b63",
   "metadata": {},
   "source": [
    "- Vector Store 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb550c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\miniconda3\\envs\\langchain\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_15412\\1459410627.py:7: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  chroma_db = Chroma(\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "검색 결과:\n",
      "- 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 벡터스토어 로드\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    embedding_function=embeddings_model,\n",
    "    collection_name=\"hf_bge_m3\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "chroma_k = chroma_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n",
    "# 벡터스토어를 사용하여 문서 검색\n",
    "query = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "retrieved_docs = chroma_k.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83a642",
   "metadata": {},
   "source": [
    "- Emsemble Hybrid Search 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17908b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "검색 결과:\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- .\n",
      "\n",
      "2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년에 비해 37.65% 증가했습니다. 2012년부터 2023년 3분기까지 테슬라의 전 세계 누적 판매량은 4,962,975대를 초과했습니다. SMT Packaging에 따르면, 2023년 테슬라의 판매량은 전 세계 전기차 시장의 약 12.9%를 차지했습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.) [출처: 리비안_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.) [출처: 리비안_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- .\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "\n",
    "# 검색기 초기화 \n",
    "def create_hybrid_retriever(bm25_db, vector_db, k: int = 4):\n",
    "\n",
    "    bm25_db.k = k\n",
    "    chroma_k = vector_db.as_retriever(search_kwargs={'k': k})\n",
    "\n",
    "    retriever = EnsembleRetriever(\n",
    "        retrievers=[bm25_db, chroma_k],\n",
    "        weights=[0.5, 0.5],\n",
    "    )\n",
    "\n",
    "    return retriever\n",
    "\n",
    "hybrid_retriever = create_hybrid_retriever(bm25_db, chroma_db, k=4)\n",
    "\n",
    "query = \"테슬라의 회장은 누구인가요?\"\n",
    "retrieved_docs = hybrid_retriever.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de555f3",
   "metadata": {},
   "source": [
    "- Cross-Encoder 알고리즘에 기반하여 재정렬 (Re-rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "207ad64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라 회장은 누구인가요?\n",
      "검색 결과:\n",
      "- 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.) [출처: 리비안_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "re_ranker = CrossEncoderReranker(model=model, top_n=3)\n",
    "\n",
    "cross_encoder_reranker_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=re_ranker, \n",
    "    base_retriever=hybrid_retriever,\n",
    ")\n",
    "\n",
    "question = \"테슬라 회장은 누구인가요?\"\n",
    "\n",
    "retrieved_docs = cross_encoder_reranker_retriever.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5781f4",
   "metadata": {},
   "source": [
    "## 3. LLM 유형 및 답변 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f1066",
   "metadata": {},
   "source": [
    "### 3-1 RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b94247f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 쿼리에 대한 검색 결과를 한꺼번에 Context로 전달해서 답변을 생성\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def create_rag_chain(retriever, llm):\n",
    "\n",
    "    template = \"\"\"Answer the following question based on this context. If the context is not relevant to the question, just answer with '답변에 필요한 근거를 찾지 못했습니다.'\n",
    "\n",
    "    [Context]\n",
    "    {context}\n",
    "\n",
    "    [Question]\n",
    "    {question}\n",
    "\n",
    "    [Answer]\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join([f\"{doc.page_content}\" for doc in docs])\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} \n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39e7552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "답변:\n",
      "일론 머스크입니다.\n"
     ]
    }
   ],
   "source": [
    "# RAG 체인 생성 및 테스트\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "openai_rag_chain = create_rag_chain(cross_encoder_reranker_retriever, llm)\n",
    "\n",
    "question = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "answer = openai_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"답변:\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc0afb",
   "metadata": {},
   "source": [
    "### 3-2 주요 모델 공급자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539e9c1",
   "metadata": {},
   "source": [
    "`(1) Anthropic Claude API`\n",
    "\n",
    "https://www.anthropic.com/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eb5fbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "답변:\n",
      "문서에 따르면 테슬라의 회장은 일론 머스크입니다. 문서에서 \"머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다.\"라고 명시되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# ChatAnthropic - LLM 모델 \n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# 모델 로드 \n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    temperature=0,\n",
    "    max_tokens=200, \n",
    ")\n",
    "\n",
    "# RAG 체인 생성 및 테스트\n",
    "anthropic_rag_chain = create_rag_chain(cross_encoder_reranker_retriever, llm)\n",
    "\n",
    "question = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "answer = anthropic_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"답변:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7045556",
   "metadata": {},
   "source": [
    "`(2) Google Gemini API`\n",
    "\n",
    "https://ai.google.dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7564cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "답변:\n",
      "일론 머스크입니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ChatGoogleGenerativeAI - LLM 모델 \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# 모델 로드 \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# RAG 체인 생성 및 테스트\n",
    "google_genai_rag_chain = create_rag_chain(cross_encoder_reranker_retriever, llm)\n",
    "\n",
    "question = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "answer = google_genai_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"답변:\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988de355",
   "metadata": {},
   "source": [
    "`(3) Ollama - 오픈소스 LLM`\n",
    "\n",
    "https://ollama.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d20b039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "답변:\n",
      "일론 머스크입니다.\n"
     ]
    }
   ],
   "source": [
    "# ChatOllama - LLM 모델 \n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 모델 로드 \n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.1\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 100,\n",
    ")\n",
    "\n",
    "# RAG 체인 생성 및 테스트\n",
    "ollama_rag_chain = create_rag_chain(cross_encoder_reranker_retriever, llm)\n",
    "\n",
    "question = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "answer = ollama_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"답변:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e78dd2",
   "metadata": {},
   "source": [
    "`(4) Groq API - 오픈소스 LLM`\n",
    "\n",
    "https://groq.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75a2e8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "답변:\n",
      "일론 머스크\n"
     ]
    }
   ],
   "source": [
    "# ChatGroq - LLM 모델 \n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 모델 로드 \n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=100,\n",
    ")\n",
    "\n",
    "# RAG 체인 생성 및 테스트\n",
    "groq_rag_chain = create_rag_chain(cross_encoder_reranker_retriever, llm)\n",
    "\n",
    "question = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "answer = groq_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"답변:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04483861",
   "metadata": {},
   "source": [
    "## 4. RAG 답변 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb75c5",
   "metadata": {},
   "source": [
    "### 4-1. Metric Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f7f18",
   "metadata": {},
   "source": [
    "`(1) Embedding Distance`\n",
    "- 임베딩 거리를 사용하여 예측 문자열과 참조 레이블 문자열 간의 의미적 유사성을 측정\n",
    "- 계산된 거리 점수가 낮을수록 두 문자열의 의미가 더 유사함을 나타내며, 이 방법은 단순 문자열 비교보다 더 풍부한 의미적 평가가 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1ac065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의미가 다른 문장 비교 결과: {'score': 0.101075617379074}\n",
      "의미가 비슷한 문장 비교 결과: {'score': 0.02741902364464399}\n"
     ]
    }
   ],
   "source": [
    "# LangChain EmbeddingDistanceEvalChain 활용 \n",
    "\n",
    "from langchain.evaluation import load_evaluator, EvaluatorType, EmbeddingDistance\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Evaluator 초기화\n",
    "embedding_evaluator = load_evaluator(\n",
    "    evaluator=EvaluatorType.EMBEDDING_DISTANCE,      # 임베딩 거리를 기반으로 평가\n",
    "    distance_metric=EmbeddingDistance.COSINE,        # 코사인 유사도 사용\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0), # OpenAI LLM 사용\n",
    "    )\n",
    "\n",
    "\n",
    "# 의미가 다른 문장 비교\n",
    "result1 = embedding_evaluator.evaluate_strings(prediction=\"나는 학교에 갈 것이다\", reference=\"나는 집에 있을 것이다\")\n",
    "print(\"의미가 다른 문장 비교 결과:\", result1)\n",
    "\n",
    "# 의미가 비슷한 문장 비교\n",
    "result2 = embedding_evaluator.evaluate_strings(prediction=\"나는 학교에 갈 것이다\", reference=\"나는 학교로 향할 것이다\")\n",
    "print(\"의미가 비슷한 문장 비교 결과:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14549cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>source</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>리비안의 초기 모델은 무엇인가요?</td>\n",
       "      <td>리비안의 초기 모델은 스포츠카 R1입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1의 좌석 구성은 어떻게 되나요?</td>\n",
       "      <td>R1은 2+2 좌석 구성입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1은 어떤 구조를 특징으로 하나요?</td>\n",
       "      <td>R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...</td>\n",
       "      <td>['data/테슬라_KR.txt']</td>\n",
       "      <td>['1']</td>\n",
       "      <td>테슬라는 어디에 본사를 두고 있나요?</td>\n",
       "      <td>테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...</td>\n",
       "      <td>['data/테슬라_KR.txt']</td>\n",
       "      <td>['1']</td>\n",
       "      <td>테슬라는 언제 설립되었나요?</td>\n",
       "      <td>테슬라는 2003년에 설립되었습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context                   source  \\\n",
       "0  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "1  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "2  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "3  ['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...  ['data/테슬라_KR.txt']   \n",
       "4  ['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...  ['data/테슬라_KR.txt']   \n",
       "\n",
       "  doc_id              question                                        answer  \n",
       "0  ['0']    리비안의 초기 모델은 무엇인가요?                       리비안의 초기 모델은 스포츠카 R1입니다.  \n",
       "1  ['0']   R1의 좌석 구성은 어떻게 되나요?                             R1은 2+2 좌석 구성입니다.  \n",
       "2  ['0']  R1은 어떤 구조를 특징으로 하나요?  R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.  \n",
       "3  ['1']  테슬라는 어디에 본사를 두고 있나요?                   테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.  \n",
       "4  ['1']       테슬라는 언제 설립되었나요?                          테슬라는 2003년에 설립되었습니다.  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 데이터셋에 대한 평가\n",
    "df_qa_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb96601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 리비안의 초기 모델은 무엇인가요?\n",
      "Ground Truth: 리비안의 초기 모델은 스포츠카 R1입니다.\n",
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다.\n",
      "Distance Score: {'score': 0.03528604311768424}\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 샘플에 대해 평가 - ground truth와 비교\n",
    "\n",
    "question = df_qa_test.iloc[0]['question']\n",
    "ground_truth = df_qa_test.iloc[0]['answer']\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Ground Truth:\", ground_truth)\n",
    "\n",
    "# OpenAI LLM을 사용하여 예측 생성\n",
    "openai_prediction = openai_rag_chain.invoke(question)\n",
    "print(\"Prediction:\", openai_prediction)\n",
    "\n",
    "distance_score = embedding_evaluator.evaluate_strings(prediction=openai_prediction, reference=ground_truth)\n",
    "print(\"Distance Score:\", distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef27968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페입니다.\n",
      "Distance Score: {'score': 0.05677878923512858}\n"
     ]
    }
   ],
   "source": [
    "### 다른 모델들에 대해 평가\n",
    "# Anthropiic LLM을 사용하여 예측 생성\n",
    "anthropic_prediction = anthropic_rag_chain.invoke(question)\n",
    "print(\"Prediction:\", anthropic_prediction)\n",
    "\n",
    "distance_score = embedding_evaluator.evaluate_strings(prediction=anthropic_prediction, reference=ground_truth)\n",
    "print(\"Distance Score:\", distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e464eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다. \n",
      "\n",
      "Distance Score: {'score': 0.04182225632635739}\n"
     ]
    }
   ],
   "source": [
    "# Google Generative AI LLM을 사용하여 예측 생성\n",
    "google_genai_prediction = google_genai_rag_chain.invoke(question)\n",
    "print(\"Prediction:\", google_genai_prediction)\n",
    "\n",
    "distance_score = embedding_evaluator.evaluate_strings(prediction=google_genai_prediction, reference=ground_truth)\n",
    "print(\"Distance Score:\", distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c38d0726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 스포츠카 R1(원래 이름은 Avera)입니다.\n",
      "Distance Score: {'score': 0.09345460934189409}\n"
     ]
    }
   ],
   "source": [
    "# Ollama LLM을 사용하여 예측 생성\n",
    "ollama_prediction = ollama_rag_chain.invoke(question)\n",
    "print(\"Prediction:\", ollama_prediction)\n",
    "\n",
    "distance_score = embedding_evaluator.evaluate_strings(prediction=ollama_prediction, reference=ground_truth)\n",
    "print(\"Distance Score:\", distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3b201a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페입니다.\n",
      "Distance Score: {'score': 0.05677878923512858}\n"
     ]
    }
   ],
   "source": [
    "# Groq LLM을 사용하여 예측 생성\n",
    "groq_prediction = groq_rag_chain.invoke(question)\n",
    "print(\"Prediction:\", groq_prediction)\n",
    "\n",
    "distance_score = embedding_evaluator.evaluate_strings(prediction=groq_prediction, reference=ground_truth)\n",
    "print(\"Distance Score:\", distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd2dc8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anthropic': '0.057',\n",
      " 'Google': '0.053',\n",
      " 'Groq': '0.057',\n",
      " 'Ollama': '0.254',\n",
      " 'OpenAI': '0.035'}\n"
     ]
    }
   ],
   "source": [
    "# 모든 모델에 대해 평가 결과를 비교\n",
    "\n",
    "def embedding_evaluate_all_models(question, ground_truth):\n",
    "    results = {}\n",
    "    for model_name, rag_chain in {\n",
    "        \"OpenAI\": openai_rag_chain,\n",
    "        \"Anthropic\": anthropic_rag_chain,\n",
    "        \"Google\": google_genai_rag_chain,\n",
    "        \"Ollama\": ollama_rag_chain,\n",
    "        \"Groq\": groq_rag_chain,\n",
    "    }.items():\n",
    "        prediction = rag_chain.invoke(question)\n",
    "        distance_score = embedding_evaluator.evaluate_strings(prediction=prediction, reference=ground_truth)\n",
    "        results[model_name] = f\"{distance_score['score']:.3f}\"\n",
    "    return results\n",
    "\n",
    "question = df_qa_test.iloc[0]['question']\n",
    "ground_truth = df_qa_test.iloc[0]['answer']\n",
    "\n",
    "results = embedding_evaluate_all_models(question, ground_truth)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fa7b714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpenAI</th>\n",
       "      <th>Anthropic</th>\n",
       "      <th>Google</th>\n",
       "      <th>Ollama</th>\n",
       "      <th>Groq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OpenAI Anthropic Google Ollama   Groq\n",
       "0   0.035     0.057  0.055  0.119  0.057\n",
       "1   0.004     0.092  0.057  0.067  0.012\n",
       "2  -0.000     0.016  0.025  0.128  0.345"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터셋에 대해 A/B 테스트 - 여기서는 3개만 평가 (데이터프레임으로 정리)\n",
    "\n",
    "def embedding_evaluate_qa_dataset(df_qa_test):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(3):\n",
    "        question = df_qa_test.iloc[i]['question']\n",
    "        ground_truth = df_qa_test.iloc[i]['answer']\n",
    "        result = embedding_evaluate_all_models(question, ground_truth)\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df_result_embedding = embedding_evaluate_qa_dataset(df_qa_test.iloc[:3])\n",
    "df_result_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc1df79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI       0.013000\n",
       "Google       0.045667\n",
       "Anthropic    0.055000\n",
       "Ollama       0.104667\n",
       "Groq         0.138000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding Distance가 낮을 수록 좋은 결과\n",
    "df_result_embedding.astype(float).mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f520bf",
   "metadata": {},
   "source": [
    "`(2) Cross-Encoder 활용`\n",
    "- 두 문장을 동시에 인코딩하여 직접적으로 유사성을 평가 (개별 문장을 따로 인코딩하는 일반적인 Bi-Encoder 임베딩 방식과 다름)\n",
    "- 크로스 인코더는 두 문장의 상호작용을 직접 모델링하므로, 일반적으로 더 정확한 유사성 점수를 제공\n",
    "- 이 방법은 의미적 유사성을 더 정확하게 측정할 수 있지만, 계산 비용이 더 높다는 점을 유의해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d83027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "def calculate_cross_encoder_similarity(\n",
    "        query: str, \n",
    "        prediction: str, \n",
    "        model_name: str = \"BAAI/bge-reranker-v2-m3\",\n",
    "        ) -> float:\n",
    "    \"\"\"\n",
    "    주어진 query와 prediction 사이의 의미적 유사성을 계산합니다.\n",
    "\n",
    "    Args:\n",
    "    query (str): 기준이 되는 쿼리 문장\n",
    "    prediction (str): 유사성을 비교할 예측 문장\n",
    "    model_name (str): 사용할 크로스 인코더 모델 이름 (기본값: \"BAAI/bge-reranker-v2-m3\")\n",
    "\n",
    "    Returns:\n",
    "    float: 두 문장 간의 유사성 점수\n",
    "    \"\"\"\n",
    "    # 크로스 인코더 모델을 불러옵니다.\n",
    "    cross_encoder_model = CrossEncoder(model_name)\n",
    "\n",
    "    # 크로스 인코더를 사용하여 유사성 점수를 계산합니다.\n",
    "    sentence_pairs = [[query, prediction]]\n",
    "    similarity_scores = cross_encoder_model.predict(sentence_pairs)\n",
    "\n",
    "    return similarity_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5be6ae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 리비안의 초기 모델은 무엇인가요?\n",
      "Ground Truth: 리비안의 초기 모델은 스포츠카 R1입니다.\n",
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다.\n",
      "유사성 점수: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 샘플에 대해 유사성 점수 계산 - 점수가 높을수록 더 유사함\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Ground Truth:\", ground_truth)\n",
    "print(\"Prediction:\", openai_prediction)\n",
    "\n",
    "similarity = calculate_cross_encoder_similarity(ground_truth, openai_prediction)\n",
    "print(f\"유사성 점수: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3404f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다.\n",
      "\n",
      "Anthropic\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페입니다.\n",
      "\n",
      "Google\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다. \n",
      "\n",
      "\n",
      "Ollama\n",
      "스포츠카 R1(원래 이름은 Avera)입니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다.\n",
      "\n",
      "Groq\n",
      "\n",
      "\n",
      "OpenAI\n",
      "R1의 좌석 구성은 2+2 좌석입니다.\n",
      "\n",
      "Anthropic\n",
      "문맥에 따르면 리비안의 초기 모델인 R1은 2+2 좌석의 미드 엔진 하이브리드 쿠페라고 되어 있습니다. 따라서 R1의 좌석 구성은 2+2 좌석이라고 답변할 수 있습니다.\n",
      "\n",
      "Google\n",
      "R1은 2+2 좌석의 미드 엔진 하이브리드 쿠페입니다. \n",
      "\n",
      "\n",
      "Ollama\n",
      "2+2 좌석입니다.\n",
      "\n",
      "Groq\n",
      "R1의 좌석 구성은 2+2 좌석입니다.\n",
      "\n",
      "OpenAI\n",
      "R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.\n",
      "\n",
      "Anthropic\n",
      "문맥에 따르면, R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.\n",
      "\n",
      "Google\n",
      "R1은 **모듈식 캡슐 구조**를 특징으로 합니다. 이 구조는 쉽게 교체 가능한 본체 패널을 갖추고 있습니다. \n",
      "\n",
      "\n",
      "Ollama\n",
      "모듈식 캡슐 구조입니다.\n",
      "\n",
      "Groq\n",
      "R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpenAI</th>\n",
       "      <th>Anthropic</th>\n",
       "      <th>Google</th>\n",
       "      <th>Ollama</th>\n",
       "      <th>Groq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OpenAI Anthropic Google Ollama   Groq\n",
       "0  1.000     1.000  1.000  0.474  0.000\n",
       "1  1.000     0.999  0.974  0.998  1.000\n",
       "2  1.000     1.000  1.000  0.996  1.000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 모델에 대해 평가 결과를 비교\n",
    "\n",
    "def cross_encoder_evaluate_all_models(question, ground_truth):\n",
    "    results = {}\n",
    "    for model_name, rag_chain in {\n",
    "        \"OpenAI\": openai_rag_chain,\n",
    "        \"Anthropic\": anthropic_rag_chain,\n",
    "        \"Google\": google_genai_rag_chain,\n",
    "        \"Ollama\": ollama_rag_chain,\n",
    "        \"Groq\": groq_rag_chain,\n",
    "    }.items():\n",
    "        prediction = rag_chain.invoke(question)\n",
    "        print(model_name)\n",
    "        print(prediction)\n",
    "        print()\n",
    "        similarity = calculate_cross_encoder_similarity(ground_truth, prediction)\n",
    "        results[model_name] = f\"{similarity:.3f}\"\n",
    "    return results\n",
    "\n",
    "\n",
    "# 전체 데이터셋에 대해 A/B 테스트 - 여기서는 3개만 평가 (데이터프레임으로 정리)\n",
    "\n",
    "def cross_encoder_evaluate_qa_dataset(df_qa_test):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(3):\n",
    "        question = df_qa_test.iloc[i]['question']\n",
    "        ground_truth = df_qa_test.iloc[i]['answer']\n",
    "        result = cross_encoder_evaluate_all_models(question, ground_truth)\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "df_result_cross_encoder = cross_encoder_evaluate_qa_dataset(df_qa_test.iloc[:3])\n",
    "df_result_cross_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f292ddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI       1.000000\n",
       "Anthropic    0.999667\n",
       "Google       0.991333\n",
       "Ollama       0.822667\n",
       "Groq         0.666667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Encoder Similarity가 높을 수록 좋은 결과\n",
    "df_result_cross_encoder.astype(float).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b24443",
   "metadata": {},
   "source": [
    "`(3) Rouge Metric`\n",
    "- ROUGE 메트릭은 두 문장의 유사도를 평가하는 데 널리 사용되는 방법으로, 특히 텍스트 요약과 기계 번역 분야에서 유용함\n",
    "- 단어 중첩을 기반으로 하여 계산이 빠르고 해석이 쉽다는 장점이 있지만, 깊은 의미적 유사성을 포착하는 데는 한계가 있음\n",
    "- 사용 목적과 컨텍스트에 따라 적절히 선택하거나 다른 메트릭과 조합하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38708625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from korouge_score import rouge_scorer\n",
    "from typing import List, Dict\n",
    "\n",
    "def calculate_rouge_similarity(\n",
    "        query: str, \n",
    "        prediction: str, \n",
    "        rouge_types: List[str] = ['rouge1', 'rouge2', 'rougeL'],\n",
    "        ) -> Dict[str, float]:\n",
    "    \n",
    "    \"\"\"\n",
    "    주어진 쿼리 문장과 예측 문장 사이의 선택된 ROUGE 점수를 계산합니다.\n",
    "\n",
    "    Args:\n",
    "    query (str): 기준이 되는 쿼리 문장\n",
    "    prediction (str): 유사성을 비교할 예측 문장\n",
    "    rouge_types (List[str]): 계산할 ROUGE 메트릭 리스트 (기본값: ['rouge1', 'rouge2', 'rougeL'])\n",
    "\n",
    "    Returns:\n",
    "    Dict[str, float]: 선택된 ROUGE 메트릭의 F1 점수를 포함하는 딕셔너리\n",
    "    \"\"\"\n",
    "    # 입력된 ROUGE 유형의 유효성을 검사합니다.\n",
    "    valid_rouge_types = set(['rouge1', 'rouge2', 'rougeL'])\n",
    "    rouge_types = [rt for rt in rouge_types if rt in valid_rouge_types]\n",
    "    \n",
    "    if not rouge_types:\n",
    "        raise ValueError(\"유효한 ROUGE 유형이 제공되지 않았습니다.\")\n",
    "\n",
    "    # ROUGE scorer 객체를 초기화합니다.\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_types, use_stemmer=True)\n",
    "\n",
    "    # ROUGE 점수를 계산합니다.\n",
    "    scores = scorer.score(query, prediction)\n",
    "\n",
    "    # 결과를 정리합니다.\n",
    "    result = {rouge_type: scores[rouge_type].fmeasure for rouge_type in rouge_types}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f30f525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 리비안의 초기 모델은 무엇인가요?\n",
      "Ground Truth: 리비안의 초기 모델은 스포츠카 R1입니다.\n",
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다.\n",
      "Rouge 점수: 0.6667\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 샘플에 대해 유사성 점수 계산 - 점수가 높을수록 더 유사함\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Ground Truth:\", ground_truth)\n",
    "print(\"Prediction:\", openai_prediction)\n",
    "\n",
    "rouge_scores = calculate_rouge_similarity(ground_truth, openai_prediction, ['rouge1'])\n",
    "print(f\"Rouge 점수: {rouge_scores['rouge1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b523331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpenAI</th>\n",
       "      <th>Anthropic</th>\n",
       "      <th>Google</th>\n",
       "      <th>Ollama</th>\n",
       "      <th>Groq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.609</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OpenAI Anthropic Google Ollama   Groq\n",
       "0  0.600     0.375  0.545  0.000  0.375\n",
       "1  1.000     0.080  0.000  0.000  0.000\n",
       "2  1.000     0.917  0.417  0.609  1.000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 모델에 대해 평가 결과를 비교\n",
    "\n",
    "def rouge_evaluate_all_models(question, ground_truth):\n",
    "    results = {}\n",
    "    for model_name, rag_chain in {\n",
    "        \"OpenAI\": openai_rag_chain,\n",
    "        \"Anthropic\": anthropic_rag_chain,\n",
    "        \"Google\": google_genai_rag_chain,\n",
    "        \"Ollama\": ollama_rag_chain,\n",
    "        \"Groq\": groq_rag_chain,\n",
    "    }.items():\n",
    "        prediction = rag_chain.invoke(question)\n",
    "        rouge_scores = calculate_rouge_similarity(ground_truth, prediction, ['rouge2'])\n",
    "        results[model_name] = f\"{rouge_scores['rouge2']:.3f}\"\n",
    "    return results\n",
    "\n",
    "# 전체 데이터셋에 대해 A/B 테스트 - 여기서는 3개만 평가 (데이터프레임으로 정리)\n",
    "\n",
    "def rouge_evaluate_qa_dataset(df_qa_test):\n",
    "    \n",
    "        results = []\n",
    "    \n",
    "        for i in range(3):\n",
    "            question = df_qa_test.iloc[i]['question']\n",
    "            ground_truth = df_qa_test.iloc[i]['answer']\n",
    "            result = rouge_evaluate_all_models(question, ground_truth)\n",
    "            results.append(result)\n",
    "    \n",
    "        return pd.DataFrame(results)    \n",
    "\n",
    "df_result_rouge = rouge_evaluate_qa_dataset(df_qa_test.iloc[:3])\n",
    "df_result_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd98ef2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI       0.866667\n",
       "Groq         0.458333\n",
       "Anthropic    0.457333\n",
       "Google       0.320667\n",
       "Ollama       0.203000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROUGE 점수가 높을 수록 좋은 결과\n",
    "df_result_rouge.astype(float).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31464a6c",
   "metadata": {},
   "source": [
    "## 4-2 LLM-as-judge\n",
    "- LLM은 인간과 유사한 판단을 제공할 수 있어, 단순한 단어 중첩 기반 메트릭보다 더 깊은 의미적 관련성을 포착할 수 있음   \n",
    "- Rouge와 같은 전통적인 메트릑보다 더 정교한 평가를 제동할 수 있지만, LLM의 판단에 의존하기 때문에 완전한 객관성을 보장하기는 어려움   \n",
    "- 또한 API 사용에 따른 비용과 처리 시간이 필요하다는 점을 고려해야 함   \n",
    "- 따라서 여러 평가 방법을 조합하여 사용 필요 (예를 들어, ROUGE 점수로 빠른 초기 스크리닝을 하고, 중요한 케이스에 대해서만 이 LLM 기반 평가를 수행하는 방법을 고려)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895e24b",
   "metadata": {},
   "source": [
    "(1) QA Evaluation - 사용자 질문에 대한 정확성, 관련성을 평가 (Y/N, 0/1)   \n",
    "    1. QA 평가기 : 사용자 질문에 대한 응답의 정확성을 직접적으로 평가   \n",
    "    2. CONTEXT_QA 평가기 : 더 넓은 맥락을 고려하여 응답의 정확성을 평가   \n",
    "    3. COT_QA 평가기 : cot 추론을 통해 더 심층적인 평가를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ad47a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: R1의 좌석 구성은 어떻게 되나요?\n",
      "Context: ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\\n\\n(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.)']\n",
      "Ground Truth: R1은 2+2 좌석 구성입니다.\n",
      "Prediction: dddd\n"
     ]
    }
   ],
   "source": [
    "# 2번째 샘플에 대해 예측 수행\n",
    "question = df_qa_test.iloc[1]['question']\n",
    "context = df_qa_test.iloc[1]['context']\n",
    "ground_truth = df_qa_test.iloc[1]['answer']\n",
    "#groq_prediction = groq_rag_chain.invoke(question)\n",
    "groq_prediction = \"dddd\"\n",
    "print(\"Question:\", question)\n",
    "print(\"Context:\", context)\n",
    "print(\"Ground Truth:\", ground_truth)\n",
    "print(\"Prediction:\", groq_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2c35bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': 'INCORRECT', 'value': 'INCORRECT', 'score': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# QA Evaluator 초기화\n",
    "qa_evaluator = load_evaluator(\n",
    "    evaluator=\"qa\",\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    ")\n",
    "\n",
    "# 2번째 샘플에 대해 평가 수행\n",
    "qa_eval_result = qa_evaluator.evaluate_strings(\n",
    "    input=question,\n",
    "    prediction=groq_prediction,\n",
    "    reference=ground_truth\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "qa_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d2e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# context_qa Evaluator 초기화\n",
    "qa_evaluator = load_evaluator(\n",
    "    evaluator=\"context_qa\",\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    ")\n",
    "\n",
    "# 2번째 샘플에 대해 평가 수행\n",
    "context_qa_eval_result = qa_evaluator.evaluate_strings(\n",
    "    input=question,\n",
    "    prediction=groq_prediction,\n",
    "    reference=context\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "context_qa_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d051cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      5\u001b[39m qa_evaluator = load_evaluator(\n\u001b[32m      6\u001b[39m     evaluator=\u001b[33m\"\u001b[39m\u001b[33mcot_qa\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     llm=ChatOpenAI(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, temperature=\u001b[32m0.0\u001b[39m)\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2번째 샘플에 대해 평가 수행\u001b[39;00m\n\u001b[32m     11\u001b[39m cot_qa_eval_result = qa_evaluator.evaluate_strings(\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28minput\u001b[39m=\u001b[43mquestion\u001b[49m,\n\u001b[32m     13\u001b[39m     prediction=groq_prediction,\n\u001b[32m     14\u001b[39m     reference=context\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# 결과 출력\u001b[39;00m\n\u001b[32m     18\u001b[39m cot_qa_eval_result\n",
      "\u001b[31mNameError\u001b[39m: name 'question' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# cot qa 초기화\n",
    "qa_evaluator = load_evaluator(\n",
    "    evaluator=\"cot_qa\",\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    ")\n",
    "\n",
    "# 2번째 샘플에 대해 평가 수행\n",
    "cot_qa_eval_result = qa_evaluator.evaluate_strings(\n",
    "    input=question,\n",
    "    prediction=groq_prediction,\n",
    "    reference=context\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "cot_qa_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42dd538",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cot_qa_eval_result[\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b68f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': 'QUESTION: R1의 좌석 구성은 어떻게 되나요?  \\nCONTEXT: [\\'.\\\\n\\\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\\\\n\\\\n(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.)\\']  \\nSYSTEM ANSWER: ddd  \\n\\nEVALUATION:  \\n1. Factual Accuracy:  \\n   - 평가: 시스템의 답변 \"ddd\"는 질문에 대한 정보가 전혀 포함되어 있지 않으며, 제공된 문맥에서 R1의 좌석 구성에 대한 정보(2+2 좌석)가 명확히 언급되어 있습니다. 따라서, 사실적으로 정확하지 않습니다.  \\n   - 설명: 질문은 R1의 좌석 구성에 대한 것이며, 문맥에서는 \"2+2 좌석\"이라는 구체적인 정보가 제공되었으나, 시스템의 답변은 이와 관련이 없습니다.  \\n\\n2. Relevance:  \\n   - 평가: 시스템의 답변은 질문과 전혀 관련이 없습니다.  \\n   - 설명: 질문은 R1의 좌석 구성에 대한 것이지만, \"ddd\"라는 답변은 의미가 없고 질문에 대한 적절한 답변이 아닙니다.  \\n\\n3. Completeness:  \\n   - 평가: 시스템의 답변은 질문에 대한 어떤 정보도 제공하지 않으므로, 완전성이 결여되어 있습니다.  \\n   - 설명: 질문에 대한 답변이 전혀 없기 때문에, 질문의 모든 측면을 다루지 못하고 있습니다.  \\n\\n4. Conciseness:  \\n   - 평가: 시스템의 답변은 간결함을 갖추고 있지 않으며, 의미가 없는 문자열로 구성되어 있습니다.  \\n   - 설명: \"ddd\"는 질문에 대한 유의미한 정보를 전달하지 않기 때문에, 간결함의 기준을 충족하지 않습니다.  \\n\\nOverall Assessment:  \\n시스템의 답변은 질문에 대한 정보가 전혀 없고, 문맥에서 제공된 사실과도 일치하지 않으며, 질문에 대한 적절한 답변을 제공하지 못했습니다. 따라서, 이 답변은 주요 오류를 포함하고 있으며, 질문과의 관련성도 전혀 없습니다.  \\n\\nGRADE: INCORRECT',\n",
       " 'value': 'INCORRECT',\n",
       " 'score': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COT QA Evaluator 초기화 (사용자 정의 프롬프트 사용)\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "CUSTOM_COT_QA_PROMPT = \"\"\"\n",
    "You are an expert evaluating the performance of a RAG (Retrieval-Augmented Generation) system. Your task is to assess the quality of the system's answer based on the given question, retrieved context, and the generated answer. Grade the answer as CORRECT, PARTIALLY CORRECT, or INCORRECT, and provide a detailed explanation. Please describe your evaluation process step by step to clearly show how you reached your conclusion.\n",
    "\n",
    "Use the following criteria for evaluation:\n",
    "1. Factual Accuracy: Does the answer align with the information in the retrieved context?\n",
    "2. Relevance: Does the answer appropriately address the question?\n",
    "3. Completeness: Does the answer cover all aspects of the question?\n",
    "4. Conciseness: Does the answer convey the key information without unnecessary details?\n",
    "\n",
    "Grading Criteria:\n",
    "- CORRECT: Meets all criteria with no errors\n",
    "- PARTIALLY CORRECT: Meets some criteria but has minor errors or omissions\n",
    "- INCORRECT: Contains major factual errors or is irrelevant to the question\n",
    "\n",
    "Evaluation Format:\n",
    "QUESTION: [The question content]\n",
    "CONTEXT: [The retrieved context]\n",
    "SYSTEM ANSWER: [The answer generated by the RAG system]\n",
    "EVALUATION:\n",
    "1. Factual Accuracy: [Assessment and explanation]\n",
    "2. Relevance: [Assessment and explanation]\n",
    "3. Completeness: [Assessment and explanation]\n",
    "4. Conciseness: [Assessment and explanation]\n",
    "Overall Assessment: [General evaluation summary]\n",
    "GRADE: [CORRECT / PARTIALLY CORRECT / INCORRECT]\n",
    "\n",
    "Now, please evaluate the RAG system's answer based on the provided information. Prefer to use in Korean language.\n",
    "\n",
    "QUESTION: {query}\n",
    "CONTEXT: {context}\n",
    "SYSTEM ANSWER: {result}\n",
    "EVALUATION:\n",
    "\"\"\"\n",
    "\n",
    "custom_qa_prompt = PromptTemplate.from_template(CUSTOM_COT_QA_PROMPT)\n",
    "\n",
    "custom_cot_qa_evaluator = load_evaluator(\n",
    "    evaluator=\"cot_qa\",  \n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0), # OpenAI LLM 사용\n",
    "    prompt=custom_qa_prompt                               # 사용자 지정 프롬프트 사용\n",
    "    )\n",
    "\n",
    "# 2번째 샘플에 대해 평가 수행\n",
    "custom_cot_qa_eval_result = custom_cot_qa_evaluator.evaluate_strings(\n",
    "    input=question,               # 평가에 고려할 내용: 질문\n",
    "    prediction=\"ddd\",   # 평가 대상: LLM 모델의 예측\n",
    "    reference=context,            # 평가 기준: 문맥\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "custom_cot_qa_eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4318db0",
   "metadata": {},
   "source": [
    "(2) Criteria Evaluation (No lables) - 참조 레이블(ground truth)이 없는 상황에서 모델 출력의 품질을 평가   \n",
    "   1. \"criteria\" 평가기 :   \n",
    "       목적 : 주어진 기준에 따라 예측이 기준을 만족하는지 평가   \n",
    "       출력 : 이진 점수 (예 YES/NO or 1/0)   \n",
    "   2. \"score_string\" 평가기:   \n",
    "       목적 : 주어진 기준에 따라 예측의 품질을 수치로 평가   \n",
    "       출력 : 수치 점수 (기본적으로 1-10 척도)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "975ecdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': 'To assess whether the submission meets the criteria of conciseness, I will evaluate the submission step by step.\\n\\n1. **Understanding the Input**: The input question is asking about the seating arrangement of R1. This implies that the expected response should provide specific information regarding the seating configuration.\\n\\n2. **Analyzing the Submission**: The submission provided is \"sss\". This response does not contain any relevant information about the seating arrangement of R1. It appears to be a random string of characters rather than a meaningful answer.\\n\\n3. **Evaluating Conciseness**: Conciseness means that the response should be brief but still convey the necessary information. In this case, the submission fails to provide any information at all, which means it is not concise; it is irrelevant.\\n\\n4. **Conclusion**: Since the submission does not address the question and fails to provide any relevant information, it does not meet the criterion of being concise and to the point.\\n\\nBased on this reasoning, the submission does not meet the criteria.\\n\\nN',\n",
       " 'value': 'N',\n",
       " 'score': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "#간결성 평가 - criteria 평가자 사용\n",
    "conciseness_evaluator = load_evaluator(\n",
    "    evaluator=\"criteria\",\n",
    "    criteria=\"conciseness\",\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    ")\n",
    "\n",
    "# 2번째 샘플에 대해 평가 수행\n",
    "conciseness_result = conciseness_evaluator.evaluate_strings(\n",
    "    input=question,                   # 질문 \n",
    "    prediction=\"sss\",       # 평가 대상: LLM 모델의 예측\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "conciseness_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5260736f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': 'To assess the submission based on the provided criteria, I will evaluate each criterion step by step.\\n\\n1. **Relevance**: The question asks about the seating arrangement of R1. The submission \"sss\" does not provide any information related to the seating configuration. Therefore, it does not appropriately address the question.\\n\\n2. **Conciseness**: While the submission is short and does not contain unnecessary details, it fails to convey any relevant information regarding the question. Conciseness is not sufficient if the answer is irrelevant.\\n\\n3. **Hello**: The criterion \"is hello?\" seems to be a nonsensical or unrelated criterion in this context. The submission does not include the word \"hello,\" but since this criterion does not pertain to the relevance or conciseness of the answer, it does not impact the overall assessment.\\n\\nBased on the evaluation:\\n- The submission fails the relevance criterion.\\n- The submission does not meet the conciseness criterion in a meaningful way since it lacks relevant content.\\n\\nSince the submission does not meet the relevance criterion, it cannot be considered satisfactory overall.\\n\\nThus, the final answer is:\\n\\nN',\n",
       " 'value': 'N',\n",
       " 'score': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criteria 직접 지정\n",
    "criteria_evaluator = load_evaluator(\n",
    "    evaluator=\"criteria\", \n",
    "    criteria={\n",
    "        \"relevance\": \"Does the answer appropriately address the question?\",\n",
    "        \"conciseness\": \"Does the answer convey the key information without unnecessary details?\",\n",
    "        \"hello\":\"is hello?\"\n",
    "        },\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0),\n",
    "    )\n",
    "\n",
    "# 2번째 샘플에 대해 평가 수행\n",
    "criteria_result = criteria_evaluator.evaluate_strings(\n",
    "    input=question,              # 질문 \n",
    "    prediction=\"sss\",      # 평가 대상: LLM 모델의 예측\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "criteria_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8ca9677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To assess the submission based on the provided criteria, I will evaluate each criterion step by step.\n",
      "\n",
      "1. **Relevance**: The question asks about the seating arrangement of R1. The submission \"sss\" does not provide any information related to the seating configuration. Therefore, it does not appropriately address the question.\n",
      "\n",
      "2. **Conciseness**: While the submission is short and does not contain unnecessary details, it fails to convey any relevant information regarding the question. Conciseness is not sufficient if the answer is irrelevant.\n",
      "\n",
      "3. **Hello**: The criterion \"is hello?\" seems to be a nonsensical or unrelated criterion in this context. The submission does not include the word \"hello,\" but since this criterion does not pertain to the relevance or conciseness of the answer, it does not impact the overall assessment.\n",
      "\n",
      "Based on the evaluation:\n",
      "- The submission fails the relevance criterion.\n",
      "- The submission does not meet the conciseness criterion in a meaningful way since it lacks relevant content.\n",
      "\n",
      "Since the submission does not meet the relevance criterion, it cannot be considered satisfactory overall.\n",
      "\n",
      "Thus, the final answer is:\n",
      "\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "print(criteria_result['reasoning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1243383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_string 평가자 사용\n",
    "score_string_evaluator = load_evaluator(\n",
    "    evaluator=\"score_string\", \n",
    "    criteria={\n",
    "        \"relevance\": \"How relevant is the answer to the question on a scale of 1-10?\",\n",
    "    },\n",
    "    normalize_by=10,\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0),\n",
    "    )\n",
    "\n",
    "# 2번째 샘플에 대해 평가 수행\n",
    "score_string_result = score_string_evaluator.evaluate_strings(\n",
    "    input=question,                     # 질문 \n",
    "    prediction=groq_prediction,         # 평가 대상: LLM 모델의 예측\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "score_string_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
