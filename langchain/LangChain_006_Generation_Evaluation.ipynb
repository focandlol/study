{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4019d1fe",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608326bb",
   "metadata": {},
   "source": [
    "`(1) LangSmith 설정 확인`\n",
    "- .env 파일에 아래 내용을 반영\n",
    "    - LANGCHAIN_TRACING_V2=true  \n",
    "    - LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"  \n",
    "    - LANGCHAIN_API_KEY=\"인증키를 입력하세요\"  \n",
    "    - LANGCHAIN_PROJECT=\"프로젝트명\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc3cefd",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ace4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d6566",
   "metadata": {},
   "source": [
    "`(3) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7801daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langsmith 추척 여부:  None\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Langsmith tracing 여부를 확인 (true: langsmith 추척 활성화, false: langsmith 추척 비활성화)\n",
    "print(\"langsmith 추척 여부: \", os.getenv('LANGCHAIN_TRACING_V2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc341c8c",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a116eb7",
   "metadata": {},
   "source": [
    "`(1) Raw Documents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adad21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# 문서를 로드\n",
    "from langchain_core.documents import Document\n",
    "import json\n",
    "\n",
    "final_docs = []\n",
    "\n",
    "with open('./data/final_docs_ver2.jsonl', 'rb') as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        doc = Document(page_content=item['page_content'], metadata=item['metadata'])\n",
    "        final_docs.append(doc)\n",
    "\n",
    "print(len(final_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc73b2",
   "metadata": {},
   "source": [
    "`(2) Test Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b162940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>source</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>리비안의 초기 모델은 무엇인가요?</td>\n",
       "      <td>리비안의 초기 모델은 스포츠카 R1입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1의 좌석 구성은 어떻게 되나요?</td>\n",
       "      <td>R1은 2+2 좌석 구성입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1은 어떤 구조를 특징으로 하나요?</td>\n",
       "      <td>R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...</td>\n",
       "      <td>['data/테슬라_KR.txt']</td>\n",
       "      <td>['1']</td>\n",
       "      <td>테슬라는 어디에 본사를 두고 있나요?</td>\n",
       "      <td>테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...</td>\n",
       "      <td>['data/테슬라_KR.txt']</td>\n",
       "      <td>['1']</td>\n",
       "      <td>테슬라는 언제 설립되었나요?</td>\n",
       "      <td>테슬라는 2003년에 설립되었습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context                   source  \\\n",
       "0  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "1  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "2  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "3  ['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...  ['data/테슬라_KR.txt']   \n",
       "4  ['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...  ['data/테슬라_KR.txt']   \n",
       "\n",
       "  doc_id              question                                        answer  \n",
       "0  ['0']    리비안의 초기 모델은 무엇인가요?                       리비안의 초기 모델은 스포츠카 R1입니다.  \n",
       "1  ['0']   R1의 좌석 구성은 어떻게 되나요?                             R1은 2+2 좌석 구성입니다.  \n",
       "2  ['0']  R1은 어떤 구조를 특징으로 하나요?  R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.  \n",
       "3  ['1']  테슬라는 어디에 본사를 두고 있나요?                   테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.  \n",
       "4  ['1']       테슬라는 언제 설립되었나요?                          테슬라는 2003년에 설립되었습니다.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터셋에 대한 QA 생성 결과를 리뷰한 후 다시 로드\n",
    "import pandas as pd\n",
    "\n",
    "df_qa_test = pd.read_excel(\"./data/qa_test_revised.xlsx\")\n",
    "\n",
    "df_qa_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d2368",
   "metadata": {},
   "source": [
    "`(3) 검색도구 정의`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9a519",
   "metadata": {},
   "source": [
    "-  BM25 검색기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d9739e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "검색 결과:\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.) [출처: 리비안_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BM25 검색기를 사용하기 위한 준비\n",
    "from krag.tokenizers import KiwiTokenizer\n",
    "from krag.retrievers import KiWiBM25RetrieverWithScore\n",
    "\n",
    "kiwi_tokenizer = KiwiTokenizer(model_type='knlm', typos='basic')\n",
    "\n",
    "bm25_db = KiWiBM25RetrieverWithScore(\n",
    "        documents=final_docs, \n",
    "        kiwi_tokenizer=kiwi_tokenizer, \n",
    "        k=2, \n",
    "        threshold=0.0,\n",
    "    )\n",
    "\n",
    "# BM25 검색기를 사용하여 문서 검색\n",
    "query = \"테슬라의 회장은 누구인가요?\"\n",
    "retrieved_docs = bm25_db.invoke(query, 2)\n",
    "\n",
    "# 검색 결과 출력 \n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48202b63",
   "metadata": {},
   "source": [
    "- Vector Store 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb550c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\1\\miniconda3\\envs\\langchain\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_15412\\1459410627.py:7: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  chroma_db = Chroma(\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "검색 결과:\n",
      "- 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 벡터스토어 로드\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    embedding_function=embeddings_model,\n",
    "    collection_name=\"hf_bge_m3\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "chroma_k = chroma_db.as_retriever(\n",
    "    search_kwargs={'k': 2},\n",
    ")\n",
    "\n",
    "# 벡터스토어를 사용하여 문서 검색\n",
    "query = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "retrieved_docs = chroma_k.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83a642",
   "metadata": {},
   "source": [
    "- Emsemble Hybrid Search 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17908b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "검색 결과:\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- .\n",
      "\n",
      "2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년에 비해 37.65% 증가했습니다. 2012년부터 2023년 3분기까지 테슬라의 전 세계 누적 판매량은 4,962,975대를 초과했습니다. SMT Packaging에 따르면, 2023년 테슬라의 판매량은 전 세계 전기차 시장의 약 12.9%를 차지했습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.) [출처: 리비안_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.) [출처: 리비안_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- .\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "\n",
    "# 검색기 초기화 \n",
    "def create_hybrid_retriever(bm25_db, vector_db, k: int = 4):\n",
    "\n",
    "    bm25_db.k = k\n",
    "    chroma_k = vector_db.as_retriever(search_kwargs={'k': k})\n",
    "\n",
    "    retriever = EnsembleRetriever(\n",
    "        retrievers=[bm25_db, chroma_k],\n",
    "        weights=[0.5, 0.5],\n",
    "    )\n",
    "\n",
    "    return retriever\n",
    "\n",
    "hybrid_retriever = create_hybrid_retriever(bm25_db, chroma_db, k=4)\n",
    "\n",
    "query = \"테슬라의 회장은 누구인가요?\"\n",
    "retrieved_docs = hybrid_retriever.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색 결과:\")\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de555f3",
   "metadata": {},
   "source": [
    "- Cross-Encoder 알고리즘에 기반하여 재정렬 (Re-rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "207ad64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라 회장은 누구인가요?\n",
      "검색 결과:\n",
      "- 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다\n",
      "\n",
      "(참고: 이 문서는 테슬라에 대한 정보를 담고 있습니다.) [출처: 테슬라_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다\n",
      "\n",
      "(참고: 이 문서는 리비안에 대한 정보를 담고 있습니다.) [출처: 리비안_KR.txt]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "re_ranker = CrossEncoderReranker(model=model, top_n=3)\n",
    "\n",
    "cross_encoder_reranker_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=re_ranker, \n",
    "    base_retriever=hybrid_retriever,\n",
    ")\n",
    "\n",
    "question = \"테슬라 회장은 누구인가요?\"\n",
    "\n",
    "retrieved_docs = cross_encoder_reranker_retriever.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"- {doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"-\"*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5781f4",
   "metadata": {},
   "source": [
    "## 3. LLM 유형 및 답변 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f1066",
   "metadata": {},
   "source": [
    "### 3-1 RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b94247f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 쿼리에 대한 검색 결과를 한꺼번에 Context로 전달해서 답변을 생성\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def create_rag_chain(retriever, llm):\n",
    "\n",
    "    template = \"\"\"Answer the following question based on this context. If the context is not relevant to the question, just answer with '답변에 필요한 근거를 찾지 못했습니다.'\n",
    "\n",
    "    [Context]\n",
    "    {context}\n",
    "\n",
    "    [Question]\n",
    "    {question}\n",
    "\n",
    "    [Answer]\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join([f\"{doc.page_content}\" for doc in docs])\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} \n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39e7552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "답변:\n",
      "일론 머스크입니다.\n"
     ]
    }
   ],
   "source": [
    "# RAG 체인 생성 및 테스트\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "openai_rag_chain = create_rag_chain(cross_encoder_reranker_retriever, llm)\n",
    "\n",
    "question = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "answer = openai_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"답변:\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc0afb",
   "metadata": {},
   "source": [
    "### 3-2 주요 모델 공급자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539e9c1",
   "metadata": {},
   "source": [
    "`(1) Anthropic Claude API`\n",
    "\n",
    "https://www.anthropic.com/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eb5fbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "답변:\n",
      "문서에 따르면 테슬라의 회장은 일론 머스크입니다. 문서에서 \"머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다.\"라고 명시되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# ChatAnthropic - LLM 모델 \n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# 모델 로드 \n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    temperature=0,\n",
    "    max_tokens=200, \n",
    ")\n",
    "\n",
    "# RAG 체인 생성 및 테스트\n",
    "anthropic_rag_chain = create_rag_chain(cross_encoder_reranker_retriever, llm)\n",
    "\n",
    "question = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "answer = anthropic_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"답변:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7045556",
   "metadata": {},
   "source": [
    "`(2) Google Gemini API`\n",
    "\n",
    "https://ai.google.dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7564cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "답변:\n",
      "일론 머스크입니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ChatGoogleGenerativeAI - LLM 모델 \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# 모델 로드 \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# RAG 체인 생성 및 테스트\n",
    "google_genai_rag_chain = create_rag_chain(cross_encoder_reranker_retriever, llm)\n",
    "\n",
    "question = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "answer = google_genai_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"답변:\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988de355",
   "metadata": {},
   "source": [
    "`(3) Ollama - 오픈소스 LLM`\n",
    "\n",
    "https://ollama.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d20b039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "답변:\n",
      "일론 머스크입니다.\n"
     ]
    }
   ],
   "source": [
    "# ChatOllama - LLM 모델 \n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 모델 로드 \n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.1\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 100,\n",
    ")\n",
    "\n",
    "# RAG 체인 생성 및 테스트\n",
    "ollama_rag_chain = create_rag_chain(cross_encoder_reranker_retriever, llm)\n",
    "\n",
    "question = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "answer = ollama_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"답변:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e78dd2",
   "metadata": {},
   "source": [
    "`(4) Groq API - 오픈소스 LLM`\n",
    "\n",
    "https://groq.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75a2e8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 테슬라의 회장은 누구인가요?\n",
      "답변:\n",
      "일론 머스크\n"
     ]
    }
   ],
   "source": [
    "# ChatGroq - LLM 모델 \n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 모델 로드 \n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=100,\n",
    ")\n",
    "\n",
    "# RAG 체인 생성 및 테스트\n",
    "groq_rag_chain = create_rag_chain(cross_encoder_reranker_retriever, llm)\n",
    "\n",
    "question = \"테슬라의 회장은 누구인가요?\"\n",
    "\n",
    "answer = groq_rag_chain.invoke(question)\n",
    "\n",
    "print(f\"쿼리: {question}\")\n",
    "print(\"답변:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04483861",
   "metadata": {},
   "source": [
    "## 4. RAG 답변 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb75c5",
   "metadata": {},
   "source": [
    "### 4-1. Metric Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f7f18",
   "metadata": {},
   "source": [
    "`(1) Embedding Distance`\n",
    "- 임베딩 거리를 사용하여 예측 문자열과 참조 레이블 문자열 간의 의미적 유사성을 측정\n",
    "- 계산된 거리 점수가 낮을수록 두 문자열의 의미가 더 유사함을 나타내며, 이 방법은 단순 문자열 비교보다 더 풍부한 의미적 평가가 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1ac065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의미가 다른 문장 비교 결과: {'score': 0.101075617379074}\n",
      "의미가 비슷한 문장 비교 결과: {'score': 0.02741902364464399}\n"
     ]
    }
   ],
   "source": [
    "# LangChain EmbeddingDistanceEvalChain 활용 \n",
    "\n",
    "from langchain.evaluation import load_evaluator, EvaluatorType, EmbeddingDistance\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Evaluator 초기화\n",
    "embedding_evaluator = load_evaluator(\n",
    "    evaluator=EvaluatorType.EMBEDDING_DISTANCE,      # 임베딩 거리를 기반으로 평가\n",
    "    distance_metric=EmbeddingDistance.COSINE,        # 코사인 유사도 사용\n",
    "    llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0), # OpenAI LLM 사용\n",
    "    )\n",
    "\n",
    "\n",
    "# 의미가 다른 문장 비교\n",
    "result1 = embedding_evaluator.evaluate_strings(prediction=\"나는 학교에 갈 것이다\", reference=\"나는 집에 있을 것이다\")\n",
    "print(\"의미가 다른 문장 비교 결과:\", result1)\n",
    "\n",
    "# 의미가 비슷한 문장 비교\n",
    "result2 = embedding_evaluator.evaluate_strings(prediction=\"나는 학교에 갈 것이다\", reference=\"나는 학교로 향할 것이다\")\n",
    "print(\"의미가 비슷한 문장 비교 결과:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14549cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>source</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>리비안의 초기 모델은 무엇인가요?</td>\n",
       "      <td>리비안의 초기 모델은 스포츠카 R1입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1의 좌석 구성은 어떻게 되나요?</td>\n",
       "      <td>R1은 2+2 좌석 구성입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...</td>\n",
       "      <td>['data/리비안_KR.txt']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>R1은 어떤 구조를 특징으로 하나요?</td>\n",
       "      <td>R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...</td>\n",
       "      <td>['data/테슬라_KR.txt']</td>\n",
       "      <td>['1']</td>\n",
       "      <td>테슬라는 어디에 본사를 두고 있나요?</td>\n",
       "      <td>테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...</td>\n",
       "      <td>['data/테슬라_KR.txt']</td>\n",
       "      <td>['1']</td>\n",
       "      <td>테슬라는 언제 설립되었나요?</td>\n",
       "      <td>테슬라는 2003년에 설립되었습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context                   source  \\\n",
       "0  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "1  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "2  ['.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2...  ['data/리비안_KR.txt']   \n",
       "3  ['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...  ['data/테슬라_KR.txt']   \n",
       "4  ['테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전...  ['data/테슬라_KR.txt']   \n",
       "\n",
       "  doc_id              question                                        answer  \n",
       "0  ['0']    리비안의 초기 모델은 무엇인가요?                       리비안의 초기 모델은 스포츠카 R1입니다.  \n",
       "1  ['0']   R1의 좌석 구성은 어떻게 되나요?                             R1은 2+2 좌석 구성입니다.  \n",
       "2  ['0']  R1은 어떤 구조를 특징으로 하나요?  R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.  \n",
       "3  ['1']  테슬라는 어디에 본사를 두고 있나요?                   테슬라는 텍사스주 오스틴에 본사를 두고 있습니다.  \n",
       "4  ['1']       테슬라는 언제 설립되었나요?                          테슬라는 2003년에 설립되었습니다.  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 데이터셋에 대한 평가\n",
    "df_qa_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb96601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 리비안의 초기 모델은 무엇인가요?\n",
      "Ground Truth: 리비안의 초기 모델은 스포츠카 R1입니다.\n",
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다.\n",
      "Distance Score: {'score': 0.03528604311768424}\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 샘플에 대해 평가 - ground truth와 비교\n",
    "\n",
    "question = df_qa_test.iloc[0]['question']\n",
    "ground_truth = df_qa_test.iloc[0]['answer']\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Ground Truth:\", ground_truth)\n",
    "\n",
    "# OpenAI LLM을 사용하여 예측 생성\n",
    "openai_prediction = openai_rag_chain.invoke(question)\n",
    "print(\"Prediction:\", openai_prediction)\n",
    "\n",
    "distance_score = embedding_evaluator.evaluate_strings(prediction=openai_prediction, reference=ground_truth)\n",
    "print(\"Distance Score:\", distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef27968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페입니다.\n",
      "Distance Score: {'score': 0.05677878923512858}\n"
     ]
    }
   ],
   "source": [
    "### 다른 모델들에 대해 평가\n",
    "# Anthropiic LLM을 사용하여 예측 생성\n",
    "anthropic_prediction = anthropic_rag_chain.invoke(question)\n",
    "print(\"Prediction:\", anthropic_prediction)\n",
    "\n",
    "distance_score = embedding_evaluator.evaluate_strings(prediction=anthropic_prediction, reference=ground_truth)\n",
    "print(\"Distance Score:\", distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e464eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다. \n",
      "\n",
      "Distance Score: {'score': 0.04182225632635739}\n"
     ]
    }
   ],
   "source": [
    "# Google Generative AI LLM을 사용하여 예측 생성\n",
    "google_genai_prediction = google_genai_rag_chain.invoke(question)\n",
    "print(\"Prediction:\", google_genai_prediction)\n",
    "\n",
    "distance_score = embedding_evaluator.evaluate_strings(prediction=google_genai_prediction, reference=ground_truth)\n",
    "print(\"Distance Score:\", distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c38d0726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 스포츠카 R1(원래 이름은 Avera)입니다.\n",
      "Distance Score: {'score': 0.09345460934189409}\n"
     ]
    }
   ],
   "source": [
    "# Ollama LLM을 사용하여 예측 생성\n",
    "ollama_prediction = ollama_rag_chain.invoke(question)\n",
    "print(\"Prediction:\", ollama_prediction)\n",
    "\n",
    "distance_score = embedding_evaluator.evaluate_strings(prediction=ollama_prediction, reference=ground_truth)\n",
    "print(\"Distance Score:\", distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3b201a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페입니다.\n",
      "Distance Score: {'score': 0.05677878923512858}\n"
     ]
    }
   ],
   "source": [
    "# Groq LLM을 사용하여 예측 생성\n",
    "groq_prediction = groq_rag_chain.invoke(question)\n",
    "print(\"Prediction:\", groq_prediction)\n",
    "\n",
    "distance_score = embedding_evaluator.evaluate_strings(prediction=groq_prediction, reference=ground_truth)\n",
    "print(\"Distance Score:\", distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd2dc8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anthropic': '0.057',\n",
      " 'Google': '0.053',\n",
      " 'Groq': '0.057',\n",
      " 'Ollama': '0.254',\n",
      " 'OpenAI': '0.035'}\n"
     ]
    }
   ],
   "source": [
    "# 모든 모델에 대해 평가 결과를 비교\n",
    "\n",
    "def embedding_evaluate_all_models(question, ground_truth):\n",
    "    results = {}\n",
    "    for model_name, rag_chain in {\n",
    "        \"OpenAI\": openai_rag_chain,\n",
    "        \"Anthropic\": anthropic_rag_chain,\n",
    "        \"Google\": google_genai_rag_chain,\n",
    "        \"Ollama\": ollama_rag_chain,\n",
    "        \"Groq\": groq_rag_chain,\n",
    "    }.items():\n",
    "        prediction = rag_chain.invoke(question)\n",
    "        distance_score = embedding_evaluator.evaluate_strings(prediction=prediction, reference=ground_truth)\n",
    "        results[model_name] = f\"{distance_score['score']:.3f}\"\n",
    "    return results\n",
    "\n",
    "question = df_qa_test.iloc[0]['question']\n",
    "ground_truth = df_qa_test.iloc[0]['answer']\n",
    "\n",
    "results = embedding_evaluate_all_models(question, ground_truth)\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fa7b714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpenAI</th>\n",
       "      <th>Anthropic</th>\n",
       "      <th>Google</th>\n",
       "      <th>Ollama</th>\n",
       "      <th>Groq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OpenAI Anthropic Google Ollama   Groq\n",
       "0   0.035     0.057  0.055  0.119  0.057\n",
       "1   0.004     0.092  0.057  0.067  0.012\n",
       "2  -0.000     0.016  0.025  0.128  0.345"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터셋에 대해 A/B 테스트 - 여기서는 3개만 평가 (데이터프레임으로 정리)\n",
    "\n",
    "def embedding_evaluate_qa_dataset(df_qa_test):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(3):\n",
    "        question = df_qa_test.iloc[i]['question']\n",
    "        ground_truth = df_qa_test.iloc[i]['answer']\n",
    "        result = embedding_evaluate_all_models(question, ground_truth)\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df_result_embedding = embedding_evaluate_qa_dataset(df_qa_test.iloc[:3])\n",
    "df_result_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc1df79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI       0.013000\n",
       "Google       0.045667\n",
       "Anthropic    0.055000\n",
       "Ollama       0.104667\n",
       "Groq         0.138000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding Distance가 낮을 수록 좋은 결과\n",
    "df_result_embedding.astype(float).mean().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f520bf",
   "metadata": {},
   "source": [
    "`(2) Cross-Encoder 활용`\n",
    "- 두 문장을 동시에 인코딩하여 직접적으로 유사성을 평가 (개별 문장을 따로 인코딩하는 일반적인 Bi-Encoder 임베딩 방식과 다름)\n",
    "- 크로스 인코더는 두 문장의 상호작용을 직접 모델링하므로, 일반적으로 더 정확한 유사성 점수를 제공\n",
    "- 이 방법은 의미적 유사성을 더 정확하게 측정할 수 있지만, 계산 비용이 더 높다는 점을 유의해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d83027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "def calculate_cross_encoder_similarity(\n",
    "        query: str, \n",
    "        prediction: str, \n",
    "        model_name: str = \"BAAI/bge-reranker-v2-m3\",\n",
    "        ) -> float:\n",
    "    \"\"\"\n",
    "    주어진 query와 prediction 사이의 의미적 유사성을 계산합니다.\n",
    "\n",
    "    Args:\n",
    "    query (str): 기준이 되는 쿼리 문장\n",
    "    prediction (str): 유사성을 비교할 예측 문장\n",
    "    model_name (str): 사용할 크로스 인코더 모델 이름 (기본값: \"BAAI/bge-reranker-v2-m3\")\n",
    "\n",
    "    Returns:\n",
    "    float: 두 문장 간의 유사성 점수\n",
    "    \"\"\"\n",
    "    # 크로스 인코더 모델을 불러옵니다.\n",
    "    cross_encoder_model = CrossEncoder(model_name)\n",
    "\n",
    "    # 크로스 인코더를 사용하여 유사성 점수를 계산합니다.\n",
    "    sentence_pairs = [[query, prediction]]\n",
    "    similarity_scores = cross_encoder_model.predict(sentence_pairs)\n",
    "\n",
    "    return similarity_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5be6ae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 리비안의 초기 모델은 무엇인가요?\n",
      "Ground Truth: 리비안의 초기 모델은 스포츠카 R1입니다.\n",
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다.\n",
      "유사성 점수: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 샘플에 대해 유사성 점수 계산 - 점수가 높을수록 더 유사함\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Ground Truth:\", ground_truth)\n",
    "print(\"Prediction:\", openai_prediction)\n",
    "\n",
    "similarity = calculate_cross_encoder_similarity(ground_truth, openai_prediction)\n",
    "print(f\"유사성 점수: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3404f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다.\n",
      "\n",
      "Anthropic\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페입니다.\n",
      "\n",
      "Google\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다. \n",
      "\n",
      "\n",
      "Ollama\n",
      "스포츠카 R1(원래 이름은 Avera)입니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다.\n",
      "\n",
      "Groq\n",
      "\n",
      "\n",
      "OpenAI\n",
      "R1의 좌석 구성은 2+2 좌석입니다.\n",
      "\n",
      "Anthropic\n",
      "문맥에 따르면 리비안의 초기 모델인 R1은 2+2 좌석의 미드 엔진 하이브리드 쿠페라고 되어 있습니다. 따라서 R1의 좌석 구성은 2+2 좌석이라고 답변할 수 있습니다.\n",
      "\n",
      "Google\n",
      "R1은 2+2 좌석의 미드 엔진 하이브리드 쿠페입니다. \n",
      "\n",
      "\n",
      "Ollama\n",
      "2+2 좌석입니다.\n",
      "\n",
      "Groq\n",
      "R1의 좌석 구성은 2+2 좌석입니다.\n",
      "\n",
      "OpenAI\n",
      "R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.\n",
      "\n",
      "Anthropic\n",
      "문맥에 따르면, R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.\n",
      "\n",
      "Google\n",
      "R1은 **모듈식 캡슐 구조**를 특징으로 합니다. 이 구조는 쉽게 교체 가능한 본체 패널을 갖추고 있습니다. \n",
      "\n",
      "\n",
      "Ollama\n",
      "모듈식 캡슐 구조입니다.\n",
      "\n",
      "Groq\n",
      "R1은 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 합니다.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpenAI</th>\n",
       "      <th>Anthropic</th>\n",
       "      <th>Google</th>\n",
       "      <th>Ollama</th>\n",
       "      <th>Groq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OpenAI Anthropic Google Ollama   Groq\n",
       "0  1.000     1.000  1.000  0.474  0.000\n",
       "1  1.000     0.999  0.974  0.998  1.000\n",
       "2  1.000     1.000  1.000  0.996  1.000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 모델에 대해 평가 결과를 비교\n",
    "\n",
    "def cross_encoder_evaluate_all_models(question, ground_truth):\n",
    "    results = {}\n",
    "    for model_name, rag_chain in {\n",
    "        \"OpenAI\": openai_rag_chain,\n",
    "        \"Anthropic\": anthropic_rag_chain,\n",
    "        \"Google\": google_genai_rag_chain,\n",
    "        \"Ollama\": ollama_rag_chain,\n",
    "        \"Groq\": groq_rag_chain,\n",
    "    }.items():\n",
    "        prediction = rag_chain.invoke(question)\n",
    "        print(model_name)\n",
    "        print(prediction)\n",
    "        print()\n",
    "        similarity = calculate_cross_encoder_similarity(ground_truth, prediction)\n",
    "        results[model_name] = f\"{similarity:.3f}\"\n",
    "    return results\n",
    "\n",
    "\n",
    "# 전체 데이터셋에 대해 A/B 테스트 - 여기서는 3개만 평가 (데이터프레임으로 정리)\n",
    "\n",
    "def cross_encoder_evaluate_qa_dataset(df_qa_test):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(3):\n",
    "        question = df_qa_test.iloc[i]['question']\n",
    "        ground_truth = df_qa_test.iloc[i]['answer']\n",
    "        result = cross_encoder_evaluate_all_models(question, ground_truth)\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "df_result_cross_encoder = cross_encoder_evaluate_qa_dataset(df_qa_test.iloc[:3])\n",
    "df_result_cross_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f292ddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI       1.000000\n",
       "Anthropic    0.999667\n",
       "Google       0.991333\n",
       "Ollama       0.822667\n",
       "Groq         0.666667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Encoder Similarity가 높을 수록 좋은 결과\n",
    "df_result_cross_encoder.astype(float).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b24443",
   "metadata": {},
   "source": [
    "`(3) Rouge Metric`\n",
    "- ROUGE 메트릭은 두 문장의 유사도를 평가하는 데 널리 사용되는 방법으로, 특히 텍스트 요약과 기계 번역 분야에서 유용함\n",
    "- 단어 중첩을 기반으로 하여 계산이 빠르고 해석이 쉽다는 장점이 있지만, 깊은 의미적 유사성을 포착하는 데는 한계가 있음\n",
    "- 사용 목적과 컨텍스트에 따라 적절히 선택하거나 다른 메트릭과 조합하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38708625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from korouge_score import rouge_scorer\n",
    "from typing import List, Dict\n",
    "\n",
    "def calculate_rouge_similarity(\n",
    "        query: str, \n",
    "        prediction: str, \n",
    "        rouge_types: List[str] = ['rouge1', 'rouge2', 'rougeL'],\n",
    "        ) -> Dict[str, float]:\n",
    "    \n",
    "    \"\"\"\n",
    "    주어진 쿼리 문장과 예측 문장 사이의 선택된 ROUGE 점수를 계산합니다.\n",
    "\n",
    "    Args:\n",
    "    query (str): 기준이 되는 쿼리 문장\n",
    "    prediction (str): 유사성을 비교할 예측 문장\n",
    "    rouge_types (List[str]): 계산할 ROUGE 메트릭 리스트 (기본값: ['rouge1', 'rouge2', 'rougeL'])\n",
    "\n",
    "    Returns:\n",
    "    Dict[str, float]: 선택된 ROUGE 메트릭의 F1 점수를 포함하는 딕셔너리\n",
    "    \"\"\"\n",
    "    # 입력된 ROUGE 유형의 유효성을 검사합니다.\n",
    "    valid_rouge_types = set(['rouge1', 'rouge2', 'rougeL'])\n",
    "    rouge_types = [rt for rt in rouge_types if rt in valid_rouge_types]\n",
    "    \n",
    "    if not rouge_types:\n",
    "        raise ValueError(\"유효한 ROUGE 유형이 제공되지 않았습니다.\")\n",
    "\n",
    "    # ROUGE scorer 객체를 초기화합니다.\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_types, use_stemmer=True)\n",
    "\n",
    "    # ROUGE 점수를 계산합니다.\n",
    "    scores = scorer.score(query, prediction)\n",
    "\n",
    "    # 결과를 정리합니다.\n",
    "    result = {rouge_type: scores[rouge_type].fmeasure for rouge_type in rouge_types}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f30f525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 리비안의 초기 모델은 무엇인가요?\n",
      "Ground Truth: 리비안의 초기 모델은 스포츠카 R1입니다.\n",
      "Prediction: 리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)입니다.\n",
      "Rouge 점수: 0.6667\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 샘플에 대해 유사성 점수 계산 - 점수가 높을수록 더 유사함\n",
    "\n",
    "print(\"Question:\", question)\n",
    "print(\"Ground Truth:\", ground_truth)\n",
    "print(\"Prediction:\", openai_prediction)\n",
    "\n",
    "rouge_scores = calculate_rouge_similarity(ground_truth, openai_prediction, ['rouge1'])\n",
    "print(f\"Rouge 점수: {rouge_scores['rouge1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b523331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpenAI</th>\n",
       "      <th>Anthropic</th>\n",
       "      <th>Google</th>\n",
       "      <th>Ollama</th>\n",
       "      <th>Groq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.609</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OpenAI Anthropic Google Ollama   Groq\n",
       "0  0.600     0.375  0.545  0.000  0.375\n",
       "1  1.000     0.080  0.000  0.000  0.000\n",
       "2  1.000     0.917  0.417  0.609  1.000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 모델에 대해 평가 결과를 비교\n",
    "\n",
    "def rouge_evaluate_all_models(question, ground_truth):\n",
    "    results = {}\n",
    "    for model_name, rag_chain in {\n",
    "        \"OpenAI\": openai_rag_chain,\n",
    "        \"Anthropic\": anthropic_rag_chain,\n",
    "        \"Google\": google_genai_rag_chain,\n",
    "        \"Ollama\": ollama_rag_chain,\n",
    "        \"Groq\": groq_rag_chain,\n",
    "    }.items():\n",
    "        prediction = rag_chain.invoke(question)\n",
    "        rouge_scores = calculate_rouge_similarity(ground_truth, prediction, ['rouge2'])\n",
    "        results[model_name] = f\"{rouge_scores['rouge2']:.3f}\"\n",
    "    return results\n",
    "\n",
    "# 전체 데이터셋에 대해 A/B 테스트 - 여기서는 3개만 평가 (데이터프레임으로 정리)\n",
    "\n",
    "def rouge_evaluate_qa_dataset(df_qa_test):\n",
    "    \n",
    "        results = []\n",
    "    \n",
    "        for i in range(3):\n",
    "            question = df_qa_test.iloc[i]['question']\n",
    "            ground_truth = df_qa_test.iloc[i]['answer']\n",
    "            result = rouge_evaluate_all_models(question, ground_truth)\n",
    "            results.append(result)\n",
    "    \n",
    "        return pd.DataFrame(results)    \n",
    "\n",
    "df_result_rouge = rouge_evaluate_qa_dataset(df_qa_test.iloc[:3])\n",
    "df_result_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd98ef2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI       0.866667\n",
       "Groq         0.458333\n",
       "Anthropic    0.457333\n",
       "Google       0.320667\n",
       "Ollama       0.203000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROUGE 점수가 높을 수록 좋은 결과\n",
    "df_result_rouge.astype(float).mean().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
